{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Imports\n\nimport os\nimport cv2\nimport glob\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport pandas as pd\nimport csv\nfrom random import randint\n\nimport tensorflow as tf\nimport seaborn as sns\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.utils import shuffle\nfrom skimage.transform import resize\nfrom tensorflow import keras\nfrom tensorflow.keras import Input, layers\nfrom keras.preprocessing.image import ImageDataGenerator, load_img\nfrom keras.models import Model, Sequential, load_model\nfrom keras.layers import Conv2D, MaxPool2D, MaxPooling2D, BatchNormalization, add\nfrom keras.layers.core import Activation, Dropout, Flatten, Dense\nfrom keras.layers.merge import concatenate\nfrom keras.utils.vis_utils import plot_model\nfrom keras import backend as K\nfrom keras import layers\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom sklearn.preprocessing import OneHotEncoder\nfrom tqdm.notebook import tqdm\nfrom PIL import Image\n\n%matplotlib inline","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-17T04:23:28.519678Z","iopub.execute_input":"2022-04-17T04:23:28.519997Z","iopub.status.idle":"2022-04-17T04:23:37.185598Z","shell.execute_reply.started":"2022-04-17T04:23:28.51996Z","shell.execute_reply":"2022-04-17T04:23:37.18468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\ndf1 = pd.read_csv('../input/old-gt-coords/old_left_eye.csv')\ndf2 = pd.read_csv('../input/old-gt-coords/old_right_eye.csv')\n\nassert df1.shape == df2.shape\ndf1.shape","metadata":{"execution":{"iopub.status.busy":"2022-04-16T20:50:41.55149Z","iopub.execute_input":"2022-04-16T20:50:41.552113Z","iopub.status.idle":"2022-04-16T20:50:41.911389Z","shell.execute_reply.started":"2022-04-16T20:50:41.552078Z","shell.execute_reply":"2022-04-16T20:50:41.910571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\nleft = []\nright = []\nfor index in range(170926):\n    img_name = df1.iloc[index]['img_path'][7:-2]\n    if(img_name != \"p07-day17-152\"):\n        left_eye = cv2.imread('../input/segmented-mpiigaze/left/' + img_name + '-l.jpg')\n        left_eye = cv2.cvtColor(left_eye, cv2.COLOR_BGR2RGB)\n        right_eye = cv2.imread('../input/segmented-mpiigaze/right/' + img_name + '-r.jpg')\n        right_eye = cv2.cvtColor(right_eye, cv2.COLOR_BGR2RGB)\n        left.append(left_eye)\n        right.append(right_eye)\nleft = np.array(left)\nright = np.array(right)\n\ntest_left = []\ntest_right = []\nfor index in range(170926, 213657):\n    img_name = df1.iloc[index]['img_path'][7:-2]\n    if(img_name != \"p07-day17-152\"):\n        left_eye = cv2.imread('../input/segmented-mpiigaze/left/' + img_name + '-l.jpg')\n        left_eye = cv2.cvtColor(left_eye, cv2.COLOR_BGR2RGB)\n        right_eye = cv2.imread('../input/segmented-mpiigaze/right/' + img_name + '-r.jpg')\n        right_eye = cv2.cvtColor(right_eye, cv2.COLOR_BGR2RGB)\n        test_left.append(left_eye)\n        test_right.append(right_eye)\n    \ntest_left = np.array(test_left)\ntest_right = np.array(test_right)","metadata":{"execution":{"iopub.status.busy":"2022-04-16T20:50:41.91299Z","iopub.execute_input":"2022-04-16T20:50:41.913267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from operator import itemgetter\n\nlabels = []\nfor i in range(170926):\n    name = df1.iloc[i]['img_path'][7:-2]\n    if(name != \"p07-day17-152\"):\n        a = df1.iloc[i]\n        b = df2.iloc[i]\n        a_x = a['x_coord']\n        a_y = a['y_coord']\n        b_x = b['x_coord']\n        b_y = b['y_coord']\n        labels.append([(a_x+b_x)/2, (a_y+b_y)/2])\nlabels = np.array(labels)\nlabels.shape\n\ntest_labels = []\n\nfor i in range(170926, 213657):\n    a = df1.iloc[i]\n    b = df2.iloc[i]\n    a_x = a['x_coord']\n    a_y = a['y_coord']\n    b_x = b['x_coord']\n    b_y = b['y_coord']\n    test_labels.append([(a_x+b_x)/2, (a_y+b_y)/2])\n\ntest_labels = np.array(test_labels)\ntest_labels.shape\n\nprint(len(labels))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_x_train = max(labels, key=itemgetter(0))[0]\nmax_x_test = max(test_labels, key=itemgetter(0))[0]\nmax_y_train = max(labels, key=itemgetter(1))[1]\nmax_y_test = max(test_labels, key=itemgetter(1))[1]\nprint(max_x_train)\nprint(max_x_test)\nprint(max_y_train)\nprint(max_y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for l in labels:\n    l[0] = (l[0] / max_x_train) * 10\n    l[1] = (l[1] / max_y_train) * 10\n\nfor l in test_labels:\n    l[0] = (l[0] / max_x_test) * 10\n    l[1] = (l[1] / max_y_test) * 10","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_model():\n    IMAGE_SIZE = (36, 60)\n    pretrained_model = tf.keras.applications.MobileNetV2(input_shape=[*IMAGE_SIZE, 3], include_top=False)\n    x = tf.keras.layers.Input(shape=[*IMAGE_SIZE, 3]) # input is 192x192 pixels RGB\n    pretrained_model.trainable = True\n\n    model = tf.keras.Sequential([\n        pretrained_model,\n        tf.keras.layers.GlobalAveragePooling2D(),\n        tf.keras.layers.Dense(5, activation='softmax', dtype=tf.float32) # the float32 is needed on softmax layer when using mixed precision\n    ])\n\n    model.compile(\n        optimizer='adam',\n        loss = 'categorical_crossentropy',\n        metrics=['accuracy']\n    )\n\n    return x, model\n\nx1, model1 = create_model()\nx2, model2 = create_model()","metadata":{"execution":{"iopub.status.busy":"2022-04-17T06:11:21.898603Z","iopub.execute_input":"2022-04-17T06:11:21.898947Z","iopub.status.idle":"2022-04-17T06:11:25.188459Z","shell.execute_reply.started":"2022-04-17T06:11:21.898912Z","shell.execute_reply":"2022-04-17T06:11:25.187526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.keras.utils.plot_model(model, show_shapes=True, show_dtype=True)","metadata":{"execution":{"iopub.status.busy":"2022-04-17T06:27:08.197258Z","iopub.execute_input":"2022-04-17T06:27:08.197593Z","iopub.status.idle":"2022-04-17T06:27:08.361284Z","shell.execute_reply.started":"2022-04-17T06:27:08.197557Z","shell.execute_reply":"2022-04-17T06:27:08.357518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow import keras\nfrom keras.models import Model\nfrom keras.layers import AvgPool2D, Concatenate, Conv2D, Dense, Dropout, Flatten, Input, MaxPool2D, ReLU\n\ninp1, network1 = x1, model1\ninp2, network2 = x2, model2\nembedding = Concatenate()([network1.output,  network2.output])\nd1 = Dense(15, activation='relu')(embedding)\ndrop = Dropout(.25)(d1)\noutput = Dense(2)(drop)\n\n# model = Model(inputs=[inp1, inp2], outputs=output)","metadata":{"execution":{"iopub.status.busy":"2022-04-17T06:11:33.8237Z","iopub.execute_input":"2022-04-17T06:11:33.824772Z","iopub.status.idle":"2022-04-17T06:11:33.91181Z","shell.execute_reply.started":"2022-04-17T06:11:33.824708Z","shell.execute_reply":"2022-04-17T06:11:33.91008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer='adam', loss=tf.keras.losses.MeanSquaredError())\nhistory = model.fit(x = [left], y = labels, validation_data = ([test_left], test_labels), epochs=40, batch_size=32)","metadata":{"execution":{"iopub.status.busy":"2022-04-17T05:57:14.766971Z","iopub.execute_input":"2022-04-17T05:57:14.767503Z","iopub.status.idle":"2022-04-17T05:57:14.813505Z","shell.execute_reply.started":"2022-04-17T05:57:14.767431Z","shell.execute_reply":"2022-04-17T05:57:14.811746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save(\"./final_60_36.h5\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}
