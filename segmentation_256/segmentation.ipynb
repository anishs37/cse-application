{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Imports\nimport os\nimport random\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nplt.style.use(\"ggplot\")\n%matplotlib inline\n\nfrom tqdm import tqdm_notebook, tnrange\nfrom itertools import chain\nfrom skimage.io import imread, imshow, concatenate_images\nfrom skimage.transform import resize\nfrom skimage.morphology import label\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow as tf\n\nfrom keras.models import Model, load_model\nfrom keras.layers import Input, BatchNormalization, Activation, Dense, Dropout\nfrom keras.layers.core import Lambda, RepeatVector, Reshape\nfrom keras.layers.convolutional import Conv2D, Conv2DTranspose\nfrom keras.layers.pooling import MaxPooling2D, GlobalMaxPool2D\nfrom keras.layers.merge import concatenate, add\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfrom tensorflow.keras.optimizers import Adam\nfrom keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\nfrom PIL import Image","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-07T15:55:58.651787Z","iopub.execute_input":"2022-04-07T15:55:58.652072Z","iopub.status.idle":"2022-04-07T15:56:05.598727Z","shell.execute_reply.started":"2022-04-07T15:55:58.652033Z","shell.execute_reply":"2022-04-07T15:56:05.597989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def segment_eyes_mask(array):\n    img_array_red=array[:,:,0]\n    img_array_green=array[:,:,1]\n    img_array_blue=array[:,:,2]\n    array = img_array_green\n    for x, row in enumerate(img_array_green):\n        for y, val in enumerate(row):\n            if val==255 and img_array_red[x,y]==0 and img_array_blue[x,y]==0:\n                array[x,y]=1\n            else:\n                array[x,y]=0\n    return array","metadata":{"execution":{"iopub.status.busy":"2022-04-07T15:56:05.60028Z","iopub.execute_input":"2022-04-07T15:56:05.60053Z","iopub.status.idle":"2022-04-07T15:56:05.606277Z","shell.execute_reply.started":"2022-04-07T15:56:05.600498Z","shell.execute_reply":"2022-04-07T15:56:05.605691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"patients = next(os.walk(\"../input/head-segmentation-masks\"))[1]\npatients.remove(\"labels\")\npatients.remove(\"real_photos\")\nim_per_patient =30\nX = np.zeros((len(patients)*im_per_patient, 256, 256,1), dtype=np.float32)\ny = np.zeros((len(patients)*im_per_patient, 256, 256,1), dtype=np.float32)\nimage_number=0\nfor p, patient_id_ in tqdm_notebook(enumerate(patients), total=len(patients)):\n    patient_image_ids = next(os.walk(\"../input/head-segmentation-masks/\"+patient_id_))[2]\n    print(\"length: \", len(patient_image_ids))\n    for c, img_id_ in tqdm_notebook(enumerate(patient_image_ids[:im_per_patient]), total=im_per_patient):\n        print(patient_id_+\"/\"+img_id_, image_number)\n        img = load_img(\"../input/head-segmentation-masks/\"+patient_id_+\"/\"+img_id_, grayscale=True, target_size=(256,256,1))\n        x_img = img_to_array(img)\n        delim = patient_id_.find(\"_\")\n        name = patient_id_[:delim]\n        if name!=\"male06\":\n            mask = load_img(\"../input/head-segmentation-masks/labels/\"+name+\"/\"+img_id_, target_size=(256,256,3))\n            mask = img_to_array(mask)\n            mask = segment_eyes_mask(mask)\n            mask = resize(mask, (256,256,1))\n            X[image_number]=x_img\n            y[image_number]=mask\n            image_number+=1","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-04-07T15:56:05.607495Z","iopub.execute_input":"2022-04-07T15:56:05.607946Z","iopub.status.idle":"2022-04-07T16:07:15.883365Z","shell.execute_reply.started":"2022-04-07T15:56:05.60791Z","shell.execute_reply":"2022-04-07T16:07:15.882629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, (ax1, ax2) = plt.subplots(1,2,figsize=(20,15))\nax1.imshow(X[5])\nax2.imshow(y[5])","metadata":{"execution":{"iopub.status.busy":"2022-04-07T16:07:15.888594Z","iopub.execute_input":"2022-04-07T16:07:15.889139Z","iopub.status.idle":"2022-04-07T16:07:16.657095Z","shell.execute_reply.started":"2022-04-07T16:07:15.889097Z","shell.execute_reply":"2022-04-07T16:07:16.655962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=20)\nindex=2","metadata":{"execution":{"iopub.status.busy":"2022-04-07T16:07:16.658114Z","iopub.execute_input":"2022-04-07T16:07:16.658334Z","iopub.status.idle":"2022-04-07T16:07:17.571178Z","shell.execute_reply.started":"2022-04-07T16:07:16.658306Z","shell.execute_reply":"2022-04-07T16:07:17.570567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def conv2d_block(input_tensor, n_filters, kernel_size = 3, batchnorm = True):\n    x = Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size),\\\n              kernel_initializer = 'he_normal', padding = 'same')(input_tensor)\n\n    if batchnorm:\n        x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    \n    return x\n  \ndef get_unet(input_img, n_filters = 16, dropout = 0.1, batchnorm = True):\n    c1 = conv2d_block(input_img, n_filters * 1, kernel_size = 3, batchnorm = batchnorm)\n    p1 = MaxPooling2D((2, 2))(c1)\n    p1 = Dropout(dropout)(p1)\n    \n    c2 = conv2d_block(p1, n_filters * 2, kernel_size = 3, batchnorm = batchnorm)\n    p2 = MaxPooling2D((2, 2))(c2)\n    p2 = Dropout(dropout)(p2)\n    \n    c3 = conv2d_block(p2, n_filters * 4, kernel_size = 3, batchnorm = batchnorm)\n    p3 = MaxPooling2D((2, 2))(c3)\n    p3 = Dropout(dropout)(p3)\n    \n    c4 = conv2d_block(p3, n_filters * 8, kernel_size = 3, batchnorm = batchnorm)\n    p4 = MaxPooling2D((2, 2))(c4)\n    p4 = Dropout(dropout)(p4)\n    \n    c5 = conv2d_block(p4, n_filters * 16, kernel_size = 3, batchnorm = batchnorm)\n    p5 = MaxPooling2D((2, 2))(c4)\n    p5 = Dropout(dropout)(p4)\n    \n    c6 = conv2d_block(p5, n_filters = n_filters * 32, kernel_size = 3, batchnorm = batchnorm)\n    \n    u6 = Conv2DTranspose(n_filters * 16, (3, 3), strides = (2, 2), padding = 'same')(c5)\n    u6 = concatenate([u6, c5])\n    u6 = Dropout(dropout)(u6)\n    c6 = conv2d_block(u6, n_filters * 16, kernel_size = 3, batchnorm = batchnorm)\n    \n    u7 = Conv2DTranspose(n_filters * 8, (3, 3), strides = (2, 2), padding = 'same')(c5)\n    u7 = concatenate([u7, c4])\n    u7 = Dropout(dropout)(u6)\n    c7 = conv2d_block(u6, n_filters * 8, kernel_size = 3, batchnorm = batchnorm)\n    \n    u8 = Conv2DTranspose(n_filters * 4, (3, 3), strides = (2, 2), padding = 'same')(c6)\n    u8 = concatenate([u8, c3])\n    u8 = Dropout(dropout)(u7)\n    c8 = conv2d_block(u7, n_filters * 4, kernel_size = 3, batchnorm = batchnorm)\n    \n    u9 = Conv2DTranspose(n_filters * 2, (3, 3), strides = (2, 2), padding = 'same')(c7)\n    u9 = concatenate([u9, c2])\n    u9 = Dropout(dropout)(u8)\n    c9 = conv2d_block(u8, n_filters * 2, kernel_size = 3, batchnorm = batchnorm)\n    \n    u10 = Conv2DTranspose(n_filters * 1, (3, 3), strides = (2, 2), padding = 'same')(c8)\n    u10 = concatenate([u10, c1])\n    u10 = Dropout(dropout)(u10)\n    c10 = conv2d_block(u9, n_filters * 1, kernel_size = 3, batchnorm = batchnorm)\n    \n    outputs = Conv2D(1, (1, 1), activation='sigmoid')(c10)\n    model = Model(inputs=[input_img], outputs=[outputs])\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-04-07T16:07:17.584005Z","iopub.execute_input":"2022-04-07T16:07:17.584259Z","iopub.status.idle":"2022-04-07T16:07:17.60283Z","shell.execute_reply.started":"2022-04-07T16:07:17.584225Z","shell.execute_reply":"2022-04-07T16:07:17.602112Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_img = Input((256, 256,1), name='img')\nmodel = get_unet(input_img, n_filters=16, dropout=0.05, batchnorm=True)\nmodel.compile(optimizer=Adam(), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-04-07T16:07:17.605219Z","iopub.execute_input":"2022-04-07T16:07:17.605645Z","iopub.status.idle":"2022-04-07T16:07:20.526848Z","shell.execute_reply.started":"2022-04-07T16:07:17.605602Z","shell.execute_reply":"2022-04-07T16:07:20.526135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"callbacks = [\n    EarlyStopping(patience=10, verbose=1),\n    ReduceLROnPlateau(factor=0.1, patience=5, min_lr=0.00001, verbose=1),\n    ModelCheckpoint('segmentation_256.h5', verbose=1, save_best_only=True, save_weights_only=True)\n]\nresults = model.fit(X_train, y_train, batch_size=32, epochs=40, callbacks=callbacks,\\\n                    validation_data=(X_valid, y_valid))","metadata":{"execution":{"iopub.status.busy":"2022-04-07T16:07:20.528125Z","iopub.execute_input":"2022-04-07T16:07:20.528369Z","iopub.status.idle":"2022-04-07T16:14:56.744049Z","shell.execute_reply.started":"2022-04-07T16:07:20.528336Z","shell.execute_reply":"2022-04-07T16:14:56.743328Z"},"trusted":true},"execution_count":null,"outputs":[]}]}